{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da3580df",
   "metadata": {},
   "source": [
    "# From the solar wind to the ground\n",
    "\n",
    "> Abstract: We demonstrate a basic analysis of a geomagnetic storm using hapiclient & viresclient to access data from the solar wind (OMNI IMF), Low Earth Orbit (Swarm-derived auroral electrojet estimates), and the ground (INTERMAGNET observatory magnetic measurements).\n",
    "\n",
    "\n",
    "## Packages to use\n",
    "\n",
    "- [`hapiclient`](https://github.com/hapi-server/client-python) to access solar wind data from [OMNI](https://omniweb.gsfc.nasa.gov/) (alternatively we could use [`pysat`](https://pysat.readthedocs.io/en/latest/quickstart.html))\n",
    "    - For more examples with hapiclient, take a look at [the demonstration notebooks](https://github.com/hapi-server/client-python-notebooks)\n",
    "- [`viresclient`](https://github.com/ESA-VirES/VirES-Python-Client/) to access AEJs from Swarm, and B-field from ground observatories\n",
    "- [`xarray`](https://xarray.pydata.org/) and [`matplotlib`](https://matplotlib.org/) for data wrangling and plotting\n",
    "    - See the [xarray tutorial website](https://xarray-contrib.github.io/xarray-tutorial/) to learn more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b29bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -i -v -p viresclient,hapiclient,pandas,xarray,matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d62988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from viresclient import SwarmRequest\n",
    "from hapiclient import hapi, hapitime2datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df87dcf",
   "metadata": {},
   "source": [
    "## Time selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a4241",
   "metadata": {},
   "source": [
    "Let's choose an interesting time period to study - the [\"St. Patrick's day storm\" of 17th March 2015](https://doi.org/10.1186/s40623-016-0525-y). You can look at the wider context of this event using the interactive [Space Weather Data Portal from the University of Colorado](https://lasp.colorado.edu/space-weather-portal/data/display?active-range=%5B1425967200000,1426831200000%5D&outer-range=%5B1262552105447,1559362748308%5D&plots=%5B%7B%22datasets%22:%7B%22sdo_eve_diodes_l2%22:%5B%22diode171%22%5D%7D,%22options%22:%7B%7D%7D,%7B%22datasets%22:%7B%22sdo_aia_0094_0335_0193_image_files%22:%5B%22url%22%5D%7D,%22options%22:%7B%7D%7D,%7B%22datasets%22:%7B%22ac_h0_mfi%22:%5B%22Magnitude%22%5D%7D,%22options%22:%7B%7D%7D,%7B%22datasets%22:%7B%22ac_h1_epm%22:%5B%22P7%22,%22P8%22%5D%7D,%22options%22:%7B%7D%7D,%7B%22datasets%22:%7B%22ac_h0_swe%22:%5B%22Vp%22%5D%7D,%22options%22:%7B%7D%7D,%7B%22datasets%22:%7B%22gracea_density%22:%5B%22neutral_density%22%5D%7D,%22options%22:%7B%7D%7D,%7B%22datasets%22:%7B%22usgs_geomag_brw_definitive%22:%5B%22X%22%5D,%22usgs_geomag_frn_definitive%22:%5B%22X%22%5D,%22usgs_geomag_cmo_definitive%22:%5B%22X%22%5D%7D,%22options%22:%7B%7D%7D,%7B%22datasets%22:%7B%22usgs_geomag_brw_definitive%22:%5B%22Y%22%5D,%22usgs_geomag_frn_definitive%22:%5B%22Y%22%5D,%22usgs_geomag_cmo_definitive%22:%5B%22Y%22%5D%7D,%22options%22:%7B%7D%7D,%7B%22datasets%22:%7B%22usgs_geomag_brw_definitive%22:%5B%22Z%22%5D,%22usgs_geomag_frn_definitive%22:%5B%22Z%22%5D,%22usgs_geomag_cmo_definitive%22:%5B%22Z%22%5D%7D,%22options%22:%7B%7D%7D,%7B%22datasets%22:%7B%22swt_bfield_maps%22:%5B%22url%22%5D%7D,%22options%22:%7B%7D%7D,%7B%22datasets%22:%7B%22swt_efield_maps%22:%5B%22url%22%5D%7D,%22options%22:%7B%7D%7D,%7B%22datasets%22:%7B%22swt_voltage_maps%22:%5B%22url%22%5D%7D,%22options%22:%7B%7D%7D%5D)\n",
    "\n",
    "We will use the same time window to fetch data from the different sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45ad6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TIME = '2015-03-15T00:00:00Z'\n",
    "END_TIME = '2015-03-20T00:00:00Z'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b7b71a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Solar wind data (OMNI)\n",
    "\n",
    "HAPI is an access protocol supported by a wide array of heliophysics datasets. We can use the Python package \"hapiclient\" to retrieve data from HAPI servers. In this case we will access the [OMNI HRO2 dataset](https://omniweb.gsfc.nasa.gov/html/HROdocum.html) which provides consolidated solar wind data, and then we will show how we can load these data into pandas and xarray objects.\n",
    "\n",
    "> OMNI Combined, Definitive 1-minute IMF and Definitive Plasma Data Time-Shifted to the Nose of the Earth's Bow Shock, plus Magnetic Indices - J.H. King, N. Papatashvilli (AdnetSystems, NASA GSFC)\n",
    "\n",
    "To generate code snippets to use, and to see what data are available:  \n",
    "http://hapi-server.org/servers/#server=CDAWeb&dataset=OMNI_HRO2_1MIN&parameters=flow_speed&start=2000-01-01T00:00:00Z&stop=2000-02-01T00:00:00Z&return=script&format=python\n",
    "\n",
    "Here we will access five-minute-resolution measurements of the Interplanetary Magnetic Field (IMF) vector and the bulk flow speed of the solar wind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40914f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_omni_data(start, stop):\n",
    "    server     = 'https://cdaweb.gsfc.nasa.gov/hapi'\n",
    "    dataset    = 'OMNI_HRO2_5MIN'\n",
    "    parameters = 'BX_GSE,BY_GSM,BZ_GSM,flow_speed';\n",
    "    data, meta = hapi(server, dataset, parameters, start, stop)\n",
    "    return data, meta\n",
    "\n",
    "data, meta = fetch_omni_data(START_TIME, END_TIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab593fe0",
   "metadata": {},
   "source": [
    "Data are automatically loaded as a [NumPy structured array](https://numpy.org/doc/stable/user/basics.rec.html) and metadata as a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6862a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a988a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23c00d5",
   "metadata": {},
   "source": [
    "We are now able to extract an array for a particular value like `data[\"BZ_GSM\"]`, and use the metadata to get full descriptions and units for the chosen parameter.\n",
    "\n",
    "The metadata sometimes contains fill values used during data gaps (e.g. the 9999... values appearing above). Let's use those to replace the gaps with NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6212d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill2nan(hapidata_in, hapimeta):\n",
    "    \"\"\"Replace bad values (fill values given in metadata) with NaN\"\"\"\n",
    "    hapidata = deepcopy(hapidata_in)\n",
    "    # HAPI returns metadata for parameters as a list of dictionaries\n",
    "    # - Loop through them\n",
    "    for metavar in hapimeta['parameters']:  \n",
    "        varname = metavar['name']\n",
    "        fillvalstr = metavar['fill']\n",
    "        if fillvalstr is None:\n",
    "            continue\n",
    "        vardata = hapidata[varname]\n",
    "        mask = vardata==float(fillvalstr)\n",
    "        nbad = np.count_nonzero(mask)\n",
    "        print('{}: {} fills NaNd'.format(varname, nbad))\n",
    "        vardata[mask] = np.nan\n",
    "    return hapidata, hapimeta\n",
    "\n",
    "data, meta = fill2nan(data,meta)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dd60e5",
   "metadata": {},
   "source": [
    "We can load the data into a pandas DataFrame to more readily use for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0260a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pandas(hapidata):\n",
    "    df = pd.DataFrame(\n",
    "        columns=hapidata.dtype.names,\n",
    "        data=hapidata,\n",
    "    ).set_index(\"Time\")\n",
    "    # Convert from hapitime to Python datetime\n",
    "    df.index = hapitime2datetime(df.index.values.astype(str))\n",
    "    # df.index = pd.DatetimeIndex(df.index.values.astype(str))\n",
    "    # Remove timezone awareness\n",
    "    df.index = df.index.tz_convert(\"UTC\").tz_convert(None)\n",
    "    # Rename to Timestamp to match viresclient\n",
    "    df.index.name = \"Timestamp\"\n",
    "    return df\n",
    "\n",
    "df = to_pandas(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5df4550",
   "metadata": {},
   "source": [
    "How can we get the extra information like the units from the metadata? Let's construct dictionaries, `units` and `description`, that allow easier access to these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70872c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_units_description(meta):\n",
    "    units = {}\n",
    "    description = {}\n",
    "    for paramdict in meta[\"parameters\"]:\n",
    "        units[paramdict[\"name\"]] = paramdict.get(\"units\", None)\n",
    "        description[paramdict[\"name\"]] = paramdict.get(\"description\", None)\n",
    "    return units, description\n",
    "units, description = get_units_description(meta)\n",
    "units, description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678fd61d",
   "metadata": {},
   "source": [
    "The [`xarray.Dataset`](http://xarray.pydata.org/en/stable/data-structures.html#dataset) object has advantages for handling multi-dimensional data and for attaching of metadata like units. Let's convert the data to an `xarray.Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0118f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_xarray(hapidata, hapimeta):\n",
    "    # Here we will conveniently re-use the pandas function we just built,\n",
    "    # and use the pandas API to build the xarray Dataset.\n",
    "    # NB: if performance is important, it's better to build the Dataset directly\n",
    "    ds = to_pandas(hapidata).to_xarray()\n",
    "    units, description = get_units_description(hapimeta)\n",
    "    for param in ds:\n",
    "        ds[param].attrs = {\n",
    "            \"units\": units[param],\n",
    "            \"description\": description[param]\n",
    "        }\n",
    "    return ds\n",
    "\n",
    "ds_sw = to_xarray(data, meta)\n",
    "ds_sw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4798f622",
   "metadata": {},
   "source": [
    "Now let's plot these data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c3caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_solar_wind(ds_sw):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(15, 5))\n",
    "    for IMF_var in [\"BX_GSE\", \"BY_GSM\", \"BZ_GSM\"]:\n",
    "        ds_sw[IMF_var].plot.line(\n",
    "            x=\"Timestamp\", linewidth=1, alpha=0.8, ax=axes[0], label=IMF_var\n",
    "        )\n",
    "    axes[0].legend()\n",
    "    axes[0].set_ylabel(\"IMF\\n[nT]\")\n",
    "    axes[0].set_xlabel(\"\")\n",
    "    ds_sw[\"flow_speed\"].plot.line(\n",
    "        x=\"Timestamp\", linewidth=1, alpha=0.8, ax=axes[1]\n",
    "    )\n",
    "    axes[1].set_ylabel(\"flow_speed\\n[km/s]\")\n",
    "    axes[1].set_xlabel(\"\")\n",
    "    axes[0].grid()\n",
    "    axes[1].grid()\n",
    "    fig.suptitle(\"Interplanetary Magnetic Field and Solar Wind flow\")\n",
    "    return fig, axes\n",
    "\n",
    "fig_sw, axes_sw = plot_solar_wind(ds_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068c320",
   "metadata": {},
   "source": [
    "## Auroral electrojets as measured by Swarm\n",
    "\n",
    "Since spacecraft move, it is difficult to extract a simple time series that can be easily tracked. From the complex Swarm product portfolio, we will pick a particular derived parameter: the peak auroral electrojet intensities derived from each pass over the current system. This signal tracks reasonably well from one orbit to the next (when separated into four orbital segments - accounting for two passes over the auroral oval in different local time sectors, and over the northern and southern hemispheres).\n",
    "\n",
    "To keep things a bit simpler, we will retrieve data only from Swarm Alpha over the Northern Hemisphere. The auroral electrojet peaks and boundaries for Swarm Alpha are contained within the product named `SW_OPER_AEJAPBL_2F`. Here is how we can access these data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22367455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_Swarm_AEJ(start_time, end_time):\n",
    "    request = SwarmRequest()\n",
    "    # Meaning of AEJAPBL: (AEJ) Auroral electrojets\n",
    "    #                     (A)   Swarm Alpha\n",
    "    #                     (PBL) Peaks and boundaries from LC method\n",
    "    # J_QD is the current intensity along QD-latitude contours\n",
    "    # QDOrbitDirection is a flag (1, -1) marking the direction of the \n",
    "    #   satellite (ascending, descending) relative to the QD pole\n",
    "    # MLT is magnetic local time, evaluated according to the\n",
    "    #   quasi-dipole magnetic longitude and the sub-solar point\n",
    "    #   (see doi.org/10.1007/s11214-016-0275-y)\n",
    "    request.set_collection(\"SW_OPER_AEJAPBL_2F\")\n",
    "    request.set_products(\n",
    "        measurements=[\"J_QD\", \"PointType\"],\n",
    "        auxiliaries=[\"QDOrbitDirection\", \"MLT\"]\n",
    "    )\n",
    "    # PointType of 0 refers to WEJ (westward electrojet) peaks\n",
    "    # PointType of 1 refers to EEJ (eastward electrojet) peaks\n",
    "    # See https://nbviewer.jupyter.org/github/pacesm/jupyter_notebooks/blob/master/AEBS/AEBS_00_data_access.ipynb#AEJxPBL-product\n",
    "    request.set_range_filter(\"Latitude\", 0, 90)  # Northern hemisphere\n",
    "    request.set_range_filter(\"PointType\", 0, 1)  # Extract only peaks\n",
    "    data = request.get_between(START_TIME, END_TIME, asynchronous=False, show_progress=False)\n",
    "    ds_AEJ_peaks = data.as_xarray()\n",
    "    return ds_AEJ_peaks\n",
    "\n",
    "ds_AEJ_peaks = fetch_Swarm_AEJ(START_TIME, END_TIME)\n",
    "ds_AEJ_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a80b2f-ea57-4733-bcca-45fc85e547e5",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "Switch `asynchronous=False` to `asynchronous=True` if making longer requests\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea66d928",
   "metadata": {},
   "source": [
    "Now we need some complex logic to plot the eastward and westward electrojet intensities, separated for each local time sector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dba78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_AEJ_envelope(ds_AEJ_peaks):\n",
    "    # Masks to identify which sector the satellite is in\n",
    "    #  and which current type (WEJ/EEJ) is given\n",
    "    mask_asc = ds_AEJ_peaks[\"QDOrbitDirection\"] == 1\n",
    "    mask_desc = ds_AEJ_peaks[\"QDOrbitDirection\"] == -1\n",
    "    mask_WEJ = ds_AEJ_peaks[\"PointType\"] == 0\n",
    "    mask_EEJ = ds_AEJ_peaks[\"PointType\"] == 1\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, sharex=True, sharey=True, figsize=(15, 5))\n",
    "    # Select and plot from the ascending orbital segments\n",
    "    #  on axes 0\n",
    "    # Eastward electrojet:\n",
    "    _ds = ds_AEJ_peaks.where(mask_EEJ & mask_asc, drop=True)\n",
    "    _ds[\"J_QD\"].plot.line(x=\"Timestamp\", ax=axes[0], label=\"EEJ\")\n",
    "    # Westward electrojet:\n",
    "    _ds = ds_AEJ_peaks.where(mask_WEJ & mask_asc, drop=True)\n",
    "    _ds[\"J_QD\"].plot.line(x=\"Timestamp\", ax=axes[0], label=\"WEJ\")\n",
    "    # Identify approximate MLT of sector\n",
    "    _ds = ds_AEJ_peaks.where(mask_asc, drop=True)\n",
    "    mlt = round(float(_ds[\"MLT\"].mean()))\n",
    "    axes[0].set_ylabel(axes[0].get_ylabel() + f\"\\nMLT: ~{mlt}\")\n",
    "    # ... and for descending segments\n",
    "    #  on axes 1\n",
    "    # Eastward electrojet:\n",
    "    _ds = ds_AEJ_peaks.where(mask_EEJ & mask_desc, drop=True)\n",
    "    _ds[\"J_QD\"].plot.line(x=\"Timestamp\", ax=axes[1], label=\"EEJ\")\n",
    "    # Westward electrojet:\n",
    "    _ds = ds_AEJ_peaks.where(mask_WEJ & mask_desc, drop=True)\n",
    "    _ds[\"J_QD\"].plot.line(x=\"Timestamp\", ax=axes[1], label=\"WEJ\")\n",
    "    # Identify approximate MLT of sector\n",
    "    _ds = ds_AEJ_peaks.where(mask_desc, drop=True)\n",
    "    mlt = round(float(_ds[\"MLT\"].mean()))\n",
    "    axes[1].set_ylabel(axes[1].get_ylabel() + f\"\\nMLT: ~{mlt}\")\n",
    "    axes[1].legend()\n",
    "    axes[0].set_xlabel(\"\")\n",
    "    axes[1].set_xlabel(\"\")\n",
    "    axes[0].grid()\n",
    "    axes[1].grid()\n",
    "    fig.suptitle(\"Auroral electrojet envelope measured by Swarm Alpha\")\n",
    "    return fig, axes\n",
    "\n",
    "fig_aej, axes_aej = plot_AEJ_envelope(ds_AEJ_peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df54a5a",
   "metadata": {},
   "source": [
    "This shows us the envelope of the auroral electrojet system - how the strength of the Eastward (EEJ) and Westward (WEJ) electrojets evolve over time - but only over the two local time sectors that the spacecraft is moving through. The strengths of the electric current along the contours of Quasi-Dipole latitude, `J_QD`, have been calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08247e47",
   "metadata": {},
   "source": [
    "### Peak ground magnetic disturbances below satellite tracks\n",
    "\n",
    "Swarm also provides predictions of the location and strength of the peak disturbance on the ground (along the satellite ground-track) caused by the auroral electrojets. Note that this is from the AEJ_PBS (using the SECS method) collection rather than the AEJ_PBL (using the LC method) used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8da2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_Swarm_AEJ_disturbances(start_time, end_time):\n",
    "    request = SwarmRequest()\n",
    "    request.set_collection(\"SW_OPER_AEJAPBS_2F:GroundMagneticDisturbance\")\n",
    "    request.set_products(\n",
    "        measurements=[\"B_NE\"],\n",
    "        auxiliaries=[\"OrbitNumber\", \"QDOrbitDirection\"]\n",
    "    )\n",
    "    request.set_range_filter(\"Latitude\", 0, 90)  # Northern hemisphere only\n",
    "    data = request.get_between(start_time, end_time, asynchronous=False, show_progress=False)\n",
    "    ds = data.as_xarray()\n",
    "    # Add vector magnitude\n",
    "    ds[\"B_Total\"] = \"Timestamp\", np.sqrt((ds[\"B_NE\"].data**2).sum(axis=1))\n",
    "    ds[\"B_Total\"].attrs[\"units\"] = \"nT\"\n",
    "    return ds\n",
    "\n",
    "ds_AEJ_disturbances = fetch_Swarm_AEJ_disturbances(START_TIME, END_TIME)\n",
    "ds_AEJ_disturbances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daa7bd7",
   "metadata": {},
   "source": [
    "This dataset contains two samples per pass over each half of the auroral oval, estimating the ground location of the peak magnetic disturbance due to each of the EEJ and WEJ currents, and the associated strength (`B_NE`) of the North and East components of the disturbance. Let's look at an approximation of the overall strongest ground disturbances, by inspecting the maximum strength found over 90-minute windows (i.e. approximately each orbit):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd20b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_Swarm_ground_disturbance(ds_AEJ_disturbances):\n",
    "    fig, ax = plt.subplots(figsize=(15, 3))\n",
    "    ds_resample = ds_AEJ_disturbances.resample({'Timestamp':'90Min'}).max()\n",
    "    ds_resample[\"B_Total\"].plot.line(x=\"Timestamp\", ax=ax)\n",
    "    fig.suptitle(\"Peak ground disturbance estimated from Swarm Alpha\")\n",
    "    ax.set_ylabel(\"Magnetic disturbance\\n[nT]\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.grid()\n",
    "    return fig, ax\n",
    "\n",
    "fig_Sw_ground, ax_Sw_ground = plot_Swarm_ground_disturbance(ds_AEJ_disturbances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de61f73",
   "metadata": {},
   "source": [
    "## Ground observatory data (INTERMAGNET)\n",
    "\n",
    "> We acknowledge usage of INTERMAGNET data  \n",
    "> See <https://intermagnet.github.io/data_conditions.html> for more\n",
    "\n",
    "As well as access to Swarm data, VirES also provides access to ground observatory data from INTERMAGNET. We can fetch data from the minute resolution dataset (`SW_OPER_AUX_OBSM2_`), specifying desired observatories according to their [3-letter IAGA codes](https://www.intermagnet.org/imos/imomap-eng.php). These data have been rotated from the geodetic reference frame to the geocentric frame (NEC).\n",
    "\n",
    "We'll select three observatories in Sweden: Abisko (ABK), Lycksele (LYC) and Uppsala (UPS), which form a chain across about 10 degrees of latitude along a similar longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07cc6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_ground_obs(IAGA_codes, start_time, end_time):\n",
    "    request = SwarmRequest()\n",
    "    request.set_collection(*[f\"SW_OPER_AUX_OBSM2_:{c}\" for c in IAGA_codes], verbose=False)\n",
    "    request.set_products(\n",
    "        measurements=[\"B_NEC\", \"IAGA_code\"],\n",
    "    )\n",
    "    data = request.get_between(start_time, end_time, asynchronous=False, show_progress=False)\n",
    "    ds = data.as_xarray(reshape=True)\n",
    "    return ds\n",
    "\n",
    "ds_ground_obs = fetch_ground_obs([\"ABK\", \"LYC\", \"UPS\"], START_TIME, END_TIME)\n",
    "ds_ground_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb69d536",
   "metadata": {},
   "source": [
    "By specifiying `reshape=True` when loading the xarray object, a multi-dimensional dataset is formed with a new `IAGA_code` axis. Here we show the three vector components from each observatory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0137d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ground_obs[\"B_NEC\"].plot.line(x=\"Timestamp\", row=\"NEC\", col=\"IAGA_code\", sharey=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee674e26",
   "metadata": {},
   "source": [
    "Let's calculate $|\\frac{dB}{dt}|$ and plot that instead. This is a good indication of the GIC risk, as a more rapidly changing magnetic field will induce a larger electric field in the ground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5998953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_groundobs_dbdt(ds_ground_obs):\n",
    "    ds_ground_obs = ds_ground_obs.assign(\n",
    "        dBdt=(ds_ground_obs[\"B_NEC\"].diff(\"Timestamp\")**2).sum(dim=\"NEC\").pipe(np.sqrt)\n",
    "    )\n",
    "    fig, axes = plt.subplots(nrows=3, figsize=(15, 7), sharey=True, sharex=True)\n",
    "    for i, obs in enumerate(ds_ground_obs[\"IAGA_code\"].values):\n",
    "        _ds = ds_ground_obs.sel(IAGA_code=obs)\n",
    "        lat = np.round(float(_ds[\"Latitude\"]), 1)\n",
    "        lon = np.round(float(_ds[\"Longitude\"]), 1)\n",
    "        label = f\"{obs} (Lat {lat}, Lon {lon})\"\n",
    "        ds_ground_obs[\"dBdt\"].sel(IAGA_code=obs).plot.line(x=\"Timestamp\", ax=axes[i], label=label)\n",
    "        axes[i].set_title(\"\")\n",
    "        axes[i].legend()\n",
    "        axes[i].set_xlabel(\"\")\n",
    "        axes[i].set_ylabel(\"dB/dt\\n[nT / min]\")\n",
    "        axes[i].grid()\n",
    "        fig.tight_layout()\n",
    "    return fig, axes\n",
    "    \n",
    "fig_grdbdt, axes_grdbdt = plot_groundobs_dbdt(ds_ground_obs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
